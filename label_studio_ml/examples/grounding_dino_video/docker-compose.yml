version: "3.11"

services:
  grounding_dino_video:
    container_name: grounding_dino_video
    image: humansignal/grounding-dino-video:dev
    build:
      context: .
      args:
        TEST_ENV: ${TEST_ENV}
    environment:
      # specify these parameters if you want to use basic auth for the model server
      BASIC_AUTH_USER: ""
      BASIC_AUTH_PASS: ""
      # set the log level for the model server
      LOG_LEVEL: INFO
      WORKERS: "1"
      THREADS: "8"
      PYTHONPATH: /app

      # Label Studio connectivity
      LABEL_STUDIO_HOST: https://app.heartex.com
      LABEL_STUDIO_URL: https://app.heartex.com
      LABEL_STUDIO_API_KEY: ${LABEL_STUDIO_API_KEY}

      # Grounding DINO configuration
      GROUNDING_DINO_PROMPT: person
      GROUNDING_DINO_BOX_THRESHOLD: "0.20"
      GROUNDING_DINO_TEXT_THRESHOLD: "0.25"
      GROUNDING_DINO_DEVICE: cuda
      GROUNDING_DINO_CONFIG: GroundingDINO_SwinT_OGC.py
      GROUNDING_DINO_WEIGHTS: gdino_swint_darpa-ir-v1-1k_20_1.pth
      MODEL_SCORE_THRESHOLD: "0.5"

      # Batch size for GPU inference (default: 8)
      # Higher values = better GPU utilization but more VRAM usage
      # Recommended: 8-16 for 24GB VRAM, 4-8 for 12GB VRAM
      GROUNDING_DINO_BATCH_SIZE: "8"
      
      # Frame skipping for faster processing (default: auto)
      # - "auto": Auto-determine based on video length (recommended)
      #           >10k frames: skip=3, >5k frames: skip=2, else: skip=1
      # - "1": No skipping (process every frame)
      # - "2": Process every 2nd frame (2x speedup)
      # - "3": Process every 3rd frame (3x speedup)
      # Skipped frames use interpolated bounding boxes from keyframes.
      GROUNDING_DINO_FRAME_SKIP: "auto"

      SPARSIFY_KF_FOR_SAM: "false"

      # ==========================================================================
      # TRACKING CONFIGURATION
      # ==========================================================================
      # Use composable presets (RECOMMENDED) instead of manual parameter tuning.
      # Presets are validated and clamped to safe bounds automatically.
      #
      # Combine multiple layers with '+' to address different concerns:
      #   PLATFORM:  uav, ugv, handheld, fixed
      #   SCENE:     crowded, sparse, cluttered
      #   MOTION:    fast_motion, slow_motion, erratic
      #   DURATION:  long_video, short_clip
      #   MODALITY:  thermal, lowlight, hdr
      #   QUALITY:   high_precision, high_recall
      #
      # Examples:
      #   TRACKING_PRESET: "uav"
      #   TRACKING_PRESET: "uav+fast_motion+long_video"
      #   TRACKING_PRESET: "thermal+crowded+high_precision"
      #
      # Can also be specified via CLI: python cli.py --preset uav+long_video
      # Use --describe-preset to see computed values before running.
      #
      # UNCOMMENT ONE OF THE FOLLOWING:
      # TRACKING_PRESET: "ugv"
      # TRACKING_PRESET: "uav+long_video"
      # TRACKING_PRESET: "uav+fast_motion+long_video"
      #
      # --------------------------------------------------------------------------
      # MANUAL OVERRIDE (advanced users only)
      # --------------------------------------------------------------------------
      # If you need fine-grained control, uncomment these to override preset values.
      # These are ONLY used if TRACKING_PRESET is NOT set.
      # If TRACKING_PRESET is set, these are ignored (preset takes precedence).
      #
      # TRACKER_ACTIVATION_THRESHOLD: "0.30"  # 0.05-0.95, higher = fewer tracks
      # TRACKER_LOST_BUFFER: "100"            # 1-1800 frames, higher = better occlusion handling
      # TRACKER_MATCH_THRESHOLD: "0.40"       # 0.05-0.95, lower = more permissive matching
      # TRACKER_MIN_CONSECUTIVE_FRAMES: "8"   # 1-100, higher = filters noise

    extra_hosts:
      - "host.docker.internal:host-gateway"  # for macos and unix      
    ports:
      - "9090:9090"
    volumes:
      - "./data/server:/data"
      - "./cache_dir:/app/cache_dir"
      - "./output_frames:/app/output_frames"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
